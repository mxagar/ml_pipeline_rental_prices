{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65e2a85d",
   "metadata": {},
   "source": [
    "# NYC Short-Term Renting Price Pipeline: Modeling Trials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e60a0ed",
   "metadata": {},
   "source": [
    "This notebook is the research environment in which different modeling approaches are tried.\n",
    "\n",
    "Some cells in this notebook are replicated in the final pipeline component/step `train_random_forest`.\n",
    "\n",
    "Table of contents:\n",
    "\n",
    "- [1. Donwload Dataset](#1.-Donwload-Dataset)\n",
    "- [2. Split](#2.-Split)\n",
    "- [3. Feature Engineering and Processing Pipeline](#3.-Feature-Engineering-and-Processing-Pipeline)\n",
    "- [4. Model and Inference Pipeline](#4.-Model-and-Inference-Pipeline)\n",
    "- [5. Train](#5.-Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "81a1b66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import yaml\n",
    "import wandb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, FunctionTransformer\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline, make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95c3634",
   "metadata": {},
   "source": [
    "## 1. Donwload Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4d34cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdatamix-ai\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.4 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.21<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">exalted-puddle-12</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/datamix-ai/nyc_airbnb\" target=\"_blank\">https://wandb.ai/datamix-ai/nyc_airbnb</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/datamix-ai/nyc_airbnb/runs/1ij619f7\" target=\"_blank\">https://wandb.ai/datamix-ai/nyc_airbnb/runs/1ij619f7</a><br/>\n",
       "                Run data is saved locally in <code>/Users/mxagar/nexo/git_repositories/ml_pipeline_rental_prices/src/eda/wandb/run-20221022_152814-1ij619f7</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download the clean and segregated dataset\n",
    "# Note this dataset needs to be already in W&B\n",
    "# To that end, we need to execute these components/steps in order:\n",
    "# mlflow run . -P steps=\"download\"\n",
    "# mlflow run . -P steps=\"basic_cleaning\"\n",
    "# mlflow run . -P steps=\"data_check\"\n",
    "# mlflow run . -P steps=\"data_split\"\n",
    "run = wandb.init(project=\"nyc_airbnb\", group=\"modeling\", save_code=True)\n",
    "local_path = wandb.use_artifact(\"trainval_data.csv:latest\").file()\n",
    "df = pd.read_csv(local_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "030340c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25937108</td>\n",
       "      <td>Luxury 2 Bedroom Grand Central</td>\n",
       "      <td>168465501</td>\n",
       "      <td>Ian</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Murray Hill</td>\n",
       "      <td>40.75058</td>\n",
       "      <td>-73.97746</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>200</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22483776</td>\n",
       "      <td>THE COOL HOUSE</td>\n",
       "      <td>55197894</td>\n",
       "      <td>Erick</td>\n",
       "      <td>Queens</td>\n",
       "      <td>Woodside</td>\n",
       "      <td>40.74907</td>\n",
       "      <td>-73.90083</td>\n",
       "      <td>Private room</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2019-02-12</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28584877</td>\n",
       "      <td>Cozy bedroom available in best area of Brooklyn!</td>\n",
       "      <td>92733485</td>\n",
       "      <td>Vitaly</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Downtown Brooklyn</td>\n",
       "      <td>40.69164</td>\n",
       "      <td>-73.99055</td>\n",
       "      <td>Private room</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2018-10-16</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19388198</td>\n",
       "      <td>Charming Hotel Alternative 2\\nMount Sinai</td>\n",
       "      <td>661399</td>\n",
       "      <td>Vivianne</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>East Harlem</td>\n",
       "      <td>40.79179</td>\n",
       "      <td>-73.94506</td>\n",
       "      <td>Private room</td>\n",
       "      <td>89</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>2019-06-16</td>\n",
       "      <td>0.91</td>\n",
       "      <td>2</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6492864</td>\n",
       "      <td>Private Artisitic Room East Village</td>\n",
       "      <td>1480124</td>\n",
       "      <td>Goldwyn</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>East Village</td>\n",
       "      <td>40.72174</td>\n",
       "      <td>-73.98418</td>\n",
       "      <td>Private room</td>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2015-09-26</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                              name    host_id  \\\n",
       "0  25937108                    Luxury 2 Bedroom Grand Central  168465501   \n",
       "1  22483776                                    THE COOL HOUSE   55197894   \n",
       "2  28584877  Cozy bedroom available in best area of Brooklyn!   92733485   \n",
       "3  19388198         Charming Hotel Alternative 2\\nMount Sinai     661399   \n",
       "4   6492864               Private Artisitic Room East Village    1480124   \n",
       "\n",
       "  host_name neighbourhood_group      neighbourhood  latitude  longitude  \\\n",
       "0       Ian           Manhattan        Murray Hill  40.75058  -73.97746   \n",
       "1     Erick              Queens           Woodside  40.74907  -73.90083   \n",
       "2    Vitaly            Brooklyn  Downtown Brooklyn  40.69164  -73.99055   \n",
       "3  Vivianne           Manhattan        East Harlem  40.79179  -73.94506   \n",
       "4   Goldwyn           Manhattan       East Village  40.72174  -73.98418   \n",
       "\n",
       "         room_type  price  minimum_nights  number_of_reviews last_review  \\\n",
       "0  Entire home/apt    200              30                  0         NaN   \n",
       "1     Private room     30               5                  7  2019-02-12   \n",
       "2     Private room     50               1                  5  2018-10-16   \n",
       "3     Private room     89               3                 21  2019-06-16   \n",
       "4     Private room     82               3                 11  2015-09-26   \n",
       "\n",
       "   reviews_per_month  calculated_host_listings_count  availability_365  \n",
       "0                NaN                               4               364  \n",
       "1               0.38                               1                 0  \n",
       "2               0.54                               1                 0  \n",
       "3               0.91                               2               125  \n",
       "4               0.23                               1                 0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "303e163c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15200 entries, 0 to 15199\n",
      "Data columns (total 16 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   id                              15200 non-null  int64  \n",
      " 1   name                            15193 non-null  object \n",
      " 2   host_id                         15200 non-null  int64  \n",
      " 3   host_name                       15193 non-null  object \n",
      " 4   neighbourhood_group             15200 non-null  object \n",
      " 5   neighbourhood                   15200 non-null  object \n",
      " 6   latitude                        15200 non-null  float64\n",
      " 7   longitude                       15200 non-null  float64\n",
      " 8   room_type                       15200 non-null  object \n",
      " 9   price                           15200 non-null  int64  \n",
      " 10  minimum_nights                  15200 non-null  int64  \n",
      " 11  number_of_reviews               15200 non-null  int64  \n",
      " 12  last_review                     12186 non-null  object \n",
      " 13  reviews_per_month               12186 non-null  float64\n",
      " 14  calculated_host_listings_count  15200 non-null  int64  \n",
      " 15  availability_365                15200 non-null  int64  \n",
      "dtypes: float64(3), int64(7), object(6)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff23fe8e",
   "metadata": {},
   "source": [
    "## 2. Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fb84f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and target\n",
    "X = df\n",
    "y = X.pop(\"price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "111f4de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/val split\n",
    "# Values from config.yaml\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=X[\"neighbourhood_group\"], random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ab0005",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering and Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e25e856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's handle the categorical features first\n",
    "# Ordinal categorical are categorical values for which the order is meaningful, for example\n",
    "# for room type: 'Entire home/apt' > 'Private room' > 'Shared room'\n",
    "ordinal_categorical = [\"room_type\"]\n",
    "non_ordinal_categorical = [\"neighbourhood_group\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb560ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: we do not need to impute room_type because the type of the room\n",
    "# is mandatory on the websites, so missing values are not possible in production\n",
    "# (nor during training). That is not true for neighbourhood_group\n",
    "ordinal_categorical_preproc = OrdinalEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "935cedba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a pipeline with two steps:\n",
    "# 1 - A SimpleImputer(strategy=\"most_frequent\") to impute missing values\n",
    "# 2 - A OneHotEncoder() step to encode the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cdf7a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_ordinal_categorical_preproc = make_pipeline(\n",
    "    SimpleImputer(strategy=\"most_frequent\"),\n",
    "    OneHotEncoder()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efbd88b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's impute the numerical columns to make sure we can handle missing values\n",
    "# (note that we do not scale because the RF algorithm does not need that)\n",
    "zero_imputed = [\n",
    "    \"minimum_nights\",\n",
    "    \"number_of_reviews\",\n",
    "    \"reviews_per_month\",\n",
    "    \"calculated_host_listings_count\",\n",
    "    \"availability_365\",\n",
    "    \"longitude\",\n",
    "    \"latitude\"\n",
    "]\n",
    "zero_imputer = SimpleImputer(strategy=\"constant\", fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdc433ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A MINIMAL FEATURE ENGINEERING step:\n",
    "# we create a feature that represents the number of days passed since the last review\n",
    "# First we impute the missing review date with an old date (because there hasn't been\n",
    "# a review for a long time), and then we create a new feature from it\n",
    "def delta_date_feature(dates):\n",
    "    \"\"\"\n",
    "    Given a 2d array containing dates (in any format recognized by pd.to_datetime), it returns the delta in days\n",
    "    between each date and the most recent date in its column\n",
    "    \"\"\"\n",
    "    date_sanitized = pd.DataFrame(dates).apply(pd.to_datetime)\n",
    "    return date_sanitized.apply(lambda d: (d.max() -d).dt.days, axis=0).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68b612c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_imputer = make_pipeline(\n",
    "    SimpleImputer(strategy='constant', fill_value='2010-01-01'),\n",
    "    FunctionTransformer(delta_date_feature, check_inverse=False, validate=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b58daf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some minimal NLP for the \"name\" column\n",
    "max_tfidf_features = 5 # from config.yaml\n",
    "reshape_to_1d = FunctionTransformer(np.reshape, kw_args={\"newshape\": -1})\n",
    "name_tfidf = make_pipeline(\n",
    "    SimpleImputer(strategy=\"constant\", fill_value=\"\"),\n",
    "    reshape_to_1d,\n",
    "    TfidfVectorizer(\n",
    "        binary=False,\n",
    "        max_features=max_tfidf_features,\n",
    "        stop_words='english'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97318a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIPELINE\n",
    "# Let's put everything together\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"ordinal_cat\", ordinal_categorical_preproc, ordinal_categorical),\n",
    "        (\"non_ordinal_cat\", non_ordinal_categorical_preproc, non_ordinal_categorical),\n",
    "        (\"impute_zero\", zero_imputer, zero_imputed),\n",
    "        (\"transform_date\", date_imputer, [\"last_review\"]),\n",
    "        (\"transform_name\", name_tfidf, [\"name\"])\n",
    "    ],\n",
    "    remainder=\"drop\",  # This drops the columns that we do not transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e36c13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_features = ordinal_categorical + non_ordinal_categorical + zero_imputed + [\"last_review\", \"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "216f8f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['room_type', 'neighbourhood_group', 'minimum_nights', 'number_of_reviews', 'reviews_per_month', 'calculated_host_listings_count', 'availability_365', 'longitude', 'latitude', 'last_review', 'name']\n"
     ]
    }
   ],
   "source": [
    "print(processed_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3a1f73",
   "metadata": {},
   "source": [
    "## 4. Model and Inference Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b735465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config.yaml and extract dictionary\n",
    "# related to the random forest\n",
    "config = dict()\n",
    "with open(\"../../config.yaml\") as fp:\n",
    "    config = yaml.safe_load(fp)\n",
    "\n",
    "rf_config = dict(config[\"modeling\"][\"random_forest\"].items())\n",
    "rf_config['random_state'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2784a009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 100,\n",
       " 'max_depth': 15,\n",
       " 'min_samples_split': 4,\n",
       " 'min_samples_leaf': 3,\n",
       " 'n_jobs': -1,\n",
       " 'criterion': 'mae',\n",
       " 'max_features': 0.5,\n",
       " 'oob_score': True,\n",
       " 'random_state': 42}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc0874a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random forest\n",
    "random_forest = RandomForestRegressor(**rf_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "82f966b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"processor\", preprocessor),\n",
    "        (\"classifier\", random_forest),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab80f85d",
   "metadata": {},
   "source": [
    "## 5. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8e4e120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: MAE = \n",
      " -32.81049986344972\n",
      "\n",
      "Best params:\n",
      " {'classifier__max_depth': 15, 'classifier__max_features': 0.5, 'classifier__n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Define Grid Search: parameters to try, cross-validation size\n",
    "# In the production code we train the model without grid search,\n",
    "# instead, hyperparamater tuning is done with hydra sweeps.\n",
    "# Note that with hydra sweeps we also vary max_tfidf_features,\n",
    "# which is not that easy to vary here with the selected arrangement.\n",
    "# Also note that I use the complete train-val split here and apply a k-fold\n",
    "# cross-validation on it -- we should use the dedicated splits separately instead.\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_features': [0.1, 0.33, 0.5, 0.75, 1.0],\n",
    "    'classifier__max_depth': [n for n in range(5,20,5)]\n",
    "}\n",
    "# Grid search\n",
    "search = GridSearchCV(estimator=sk_pipe,\n",
    "                      param_grid=param_grid,\n",
    "                      cv=3,\n",
    "                      scoring='neg_mean_absolute_error') # Negative MAE\n",
    "# Find best hyperparameters and best estimator pipeline\n",
    "search.fit(X, y)\n",
    "# We would export this model\n",
    "rfc_pipe = search.best_estimator_\n",
    "# This is the best score\n",
    "print('Best score: MAE = \\n', search.best_score_)\n",
    "# We can export the best parameters to a YAML and load them for inference\n",
    "print('\\nBest params:\\n', search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e13f03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
